#Explora√ß√£o da estrutura do data frame - vis√£o 2
ExpData(dados,type=2)
#Explora√ß√£o da estrutura do data frame - vis√£o 3
str(dados)
#Explora√ß√£o da estrutura do data frame - vis√£o 4
plot_intro(dados)
# ajuste da vari√°vel Genero como dummy
dados$gender_cod <- as.numeric(dados$Gender == "F") #0=male e 1=female
# filtrar clientes com utiliza√ß√£o > zero
dados <- dados %>%
filter(Avg_Utilization_Ratio > 0.01)
# redu√ß√£o da amostra
dados <- dados %>%
sample_frac(0.05, replace = FALSE)
# Defina a semente para reproduzibilidade
set.seed(56)
# define a propor√ß√£o de dados que ser√° usada para treinamento (por exemplo, 0.7 para 70%)
index <- createDataPartition(dados$Total_Revolving_Bal, p = 0.7, list = FALSE)
# Crie conjuntos de treinamento e teste com base nos √≠ndices
conjunto_treinamento <- dados[index, ]
conjunto_teste <- dados[-index, ]
# validar a igualdade das amostras
boxplot(conjunto_treinamento$Total_Revolving_Bal,conjunto_teste$Total_Revolving_Bal)
# Criar um modelo de Regress√£o Linear
modelo_lin <- lm(Total_Revolving_Bal ~ Avg_Utilization_Ratio, dados)
# An√°lise gr√°fica:
par(mfrow=c(2,2))
plot(modelo_lin)
### Interpreta√ß√£o: https://data.library.virginia.edu/diagnostic-plots/
# (ES) gr√°fico Residuals vs Fitted (ajustamento dos res√≠duos), comprava a linearidade dos res√≠duos,
# para isso deve ter a linha vermelha na horizontal.
# (DS) Normal Q-Q (gr√°fico QQ Plot) demonstra a normalidade dos res√≠duos, deve ser apoiado pelo teste de Shapiro Wilk
# (EI) Scale Location (valida a homocedasticidade dos res√≠duos)
# o gr√°fico deve apresentar uma distribui√ß√£o dos pontos de forma aleat√≥ria
# (DI) Residuals vs Leverage - outliers e pontos influentes dos res√≠duos
# algo fora do padr√£o ir√° estar acima de linha pontilhada
## Normalidade dos res√≠duos:
## H0 = H√° normalidade nos dados
shapiro.test(modelo_lin$residuals)
## Outliers nos res√≠duos:
## tendo os res√≠duos estandarizados, devemos observar se algum deles passa do valor 3
summary(rstandard(modelo_lin))
## Homocedasticidade (Breusch-Pagan):H0 h√° homocedasticidade
bptest(modelo_lin)
## Independ√™ncia dos res√≠duos (Durbin-Watson): H0 autocorrela√ß√£o positiva
## contudo normalmente utilizado para estudos longitudinais com a seguinte leitura
## A estat√≠stica de teste Durbin-Watson toma valores entre 0 e 4. Ao n√≠vel de signific√¢ncia ÔÅ° de 5%: ## ùëë‚âà0, rejeita-se H0 e existe autocorrela√ß√£o positiva
## ùëë‚âà4, rejeita-se H0 e existe autocorrela√ß√£o negativa
##valores pr√≥ximos de 2, tipicamente entre 1.5 e 2.5, n√£o se rejeita H0, assumindo-se a independ√™ncia
durbinWatsonTest(modelo_lin)
## Resultados do Modelo
summary(modelo_lin)
# Fazer previs√µes
previsoes <- predict(modelo_nb, conjunto_teste)
ggplot(data = dados, mapping = aes(x = Avg_Utilization_Ratio, y = Total_Revolving_Bal)) +
geom_point() +
geom_smooth(method = "lm", col = "green") +
stat_poly_eq(aes(label = paste(after_stat(eq.label), after_stat(adj.rr.label),
sep = "*plain(\",\")~~")),
label.x = 0.5, label.y = 0.05,
parse = TRUE, coef.digits = 5) +
theme_classic()
View(conjunto_treinamento)
glimpse(dads)
glimpse(dados)
table(dados$Marital_Status)
# filtrar clientes com utiliza√ß√£o > zero
dados <- dados %>%
filter(Avg_Utilization_Ratio > 0.01) %>%
filter(Marital_Status != "Unknown")
dados <- dados %>%
table(dados$Marital_Status)
dados$marital_cod <- as.numeric(factor(dados$Marital_Status, levels = unique(dados$Marital_Status)))
levels(dados$marital_cod) <- c("Married","Single","Divorced")
table(dados$Marital_Status, dados$marital_cod)
glimpse(dados)
levels(dados$marital_cod) <- c("Married","Single","Divorced")
glimpse(dados)
summary(dados$marital_cod)
library(fastDummies)
install.packages("fastDummies")
library()
library(fastDummies)
dm <- dummy_cols(dados, select_columns = "marital_cod")
dm
dm <- dummy_cols(dados, select_columns = "marital_cod", remove_selected_columns = TRUE)
dm
table(dados$marital_cod1,dados$marital_cod2,dados$marital_cod3)
table(dados$marital_cod1,dados$marital_cod2)
table(dm$marital_cod1,dm$marital_cod2, dm$marital_cod3)
dados$Marital2 <- ifelse(dados$marital_cod == 2, 1, 0)
dados$Marital3 <- ifelse(dados$marital_cod == 3, 1, 0)
View(dados)
table(dados$marital_cod, dados$Marital2)
table(dados$marital_cod, dados$Marital3)
dados <- read.csv("BankChurners.csv")
# excluir as ultimas duas colunas para ocultar o resultado anterior do projeto
dados <- dados[ ,1:21]
#varificar se h√° alguma linha repetida
anyDuplicated(dados)
#Explora√ß√£o da estrutura do data frame - vis√£o 1
ExpData(dados,type=1)
#Explora√ß√£o da estrutura do data frame - vis√£o 2
ExpData(dados,type=2)
#Explora√ß√£o da estrutura do data frame - vis√£o 3
str(dados)
#Explora√ß√£o da estrutura do data frame - vis√£o 4
plot_intro(dados)
# ajuste da vari√°vel Genero como dummy
## Genero
dados$gender_cod <- as.numeric(dados$Gender == "F") #0=male e 1=female
##Estado Civil
dados$marital_cod <- as.numeric(factor(dados$Marital_Status, levels = unique(dados$Marital_Status)))
levels(dados$marital_cod) <- c("Married","Single","Divorced")
table(dados$Marital_Status, dados$marital_cod)
dados$Marital2 <- ifelse(dados$marital_cod == 2, 1, 0)
dados$Marital3 <- ifelse(dados$marital_cod == 3, 1, 0)
# filtrar clientes com utiliza√ß√£o > zero
dados <- dados %>%
filter(Avg_Utilization_Ratio > 0.01) %>%
filter(Marital_Status != "Unknown")
# redu√ß√£o da amostra
dados <- dados %>%
sample_frac(0.05, replace = FALSE)
glimps(dados)
glimpse(dados)
# Criar um modelo de Regress√£o Linear
modelo_lin <- lm(Total_Revolving_Bal ~ Avg_Utilization_Ratio + Dependent_count + Customer_Age + gender_cod  + Marital2 + Marital3, dados)
summary(modelo_lin)
par(mfrow=c(2,2))
plot(modelo_lin)
par(mfrow=c(2,2))
plot(modelo_lin)
## Normalidade dos res√≠duos:
## H0 = H√° normalidade nos dados
shapiro.test(modelo_lin$residuals)
plot(modelo_lin)
## Outliers nos res√≠duos:
## tendo os res√≠duos estandarizados, devemos observar se algum deles passa do valor 3
summary(rstandard(modelo_lin))
## Homocedasticidade (Breusch-Pagan):H0 h√° homocedasticidade
bptest(modelo_lin)
## Independ√™ncia dos res√≠duos (Durbin-Watson): H0 autocorrela√ß√£o positiva
## contudo normalmente utilizado para estudos longitudinais com a seguinte leitura
## A estat√≠stica de teste Durbin-Watson toma valores entre 0 e 4. Ao n√≠vel de signific√¢ncia ÔÅ° de 5%: ## ùëë‚âà0, rejeita-se H0 e existe autocorrela√ß√£o positiva
## ùëë‚âà4, rejeita-se H0 e existe autocorrela√ß√£o negativa
##valores pr√≥ximos de 2, tipicamente entre 1.5 e 2.5, n√£o se rejeita H0, assumindo-se a independ√™ncia
durbinWatsonTest(modelo_lin)
## Resultados do Modelo
summary(modelo_lin)
# Criar um modelo de Regress√£o Linear
modelo_lin <- lm(Total_Revolving_Bal ~ Avg_Utilization_Ratio + Dependent_count + Customer_Age + gender_cod  + Marital2, dados)
plot(modelo_lin)
plot(modelo_lin)
## Normalidade dos res√≠duos:
## H0 = H√° normalidade nos dados
shapiro.test(modelo_lin$residuals)
glimpse(dados)
modelo_lin <- lm(Total_Revolving_Bal ~ Avg_Utilization_Ratio + Contacts_Count_12_mon + Months_on_book + Dependent_count + Customer_Age + gender_cod  + Marital2, dados)
plot(modelo_lin)
modelo_lin <- lm(Total_Revolving_Bal ~ Avg_Utilization_Ratio + Contacts_Count_12_mon + Months_on_book + Dependent_count + Customer_Age + gender_cod  + Marital2, conjunto_treinamento)
# Defina a semente para reproduzibilidade
set.seed(56)
# define a propor√ß√£o de dados que ser√° usada para treinamento (por exemplo, 0.7 para 70%)
index <- createDataPartition(dados$Total_Revolving_Bal, p = 0.7, list = FALSE)
# Crie conjuntos de treinamento e teste com base nos √≠ndices
conjunto_treinamento <- dados[index, ]
conjunto_teste <- dados[-index, ]
# validar a igualdade das amostras
boxplot(conjunto_treinamento$Total_Revolving_Bal,conjunto_teste$Total_Revolving_Bal)
# Criar um modelo de Regress√£o Linear
modelo_lin <- lm(Total_Revolving_Bal ~ Avg_Utilization_Ratio + Contacts_Count_12_mon + Months_on_book + Dependent_count + Customer_Age + gender_cod  + Marital2, conjunto_treinamento)
# An√°lise gr√°fica:
par(mfrow=c(2,2))
plot(modelo_lin)
### Interpreta√ß√£o: https://data.library.virginia.edu/diagnostic-plots/
# (ES) gr√°fico Residuals vs Fitted (ajustamento dos res√≠duos), comprava a linearidade dos res√≠duos,
# para isso deve ter a linha vermelha na horizontal.
# (DS) Normal Q-Q (gr√°fico QQ Plot) demonstra a normalidade dos res√≠duos, deve ser apoiado pelo teste de Shapiro Wilk
# (EI) Scale Location (valida a homocedasticidade dos res√≠duos)
# o gr√°fico deve apresentar uma distribui√ß√£o dos pontos de forma aleat√≥ria
# (DI) Residuals vs Leverage - outliers e pontos influentes dos res√≠duos
# algo fora do padr√£o ir√° estar acima de linha pontilhada
## Normalidade dos res√≠duos:
## H0 = H√° normalidade nos dados
shapiro.test(modelo_lin$residuals)
## Outliers nos res√≠duos:
## tendo os res√≠duos estandarizados, devemos observar se algum deles passa do valor 3
summary(rstandard(modelo_lin))
## Homocedasticidade (Breusch-Pagan):H0 h√° homocedasticidade
bptest(modelo_lin)
## Independ√™ncia dos res√≠duos (Durbin-Watson): H0 autocorrela√ß√£o positiva
## contudo normalmente utilizado para estudos longitudinais com a seguinte leitura
## A estat√≠stica de teste Durbin-Watson toma valores entre 0 e 4. Ao n√≠vel de signific√¢ncia ÔÅ° de 5%: ## ùëë‚âà0, rejeita-se H0 e existe autocorrela√ß√£o positiva
## ùëë‚âà4, rejeita-se H0 e existe autocorrela√ß√£o negativa
##valores pr√≥ximos de 2, tipicamente entre 1.5 e 2.5, n√£o se rejeita H0, assumindo-se a independ√™ncia
durbinWatsonTest(modelo_lin)
## Resultados do Modelo
summary(modelo_lin)
# An√°lise gr√°fica:
par(mfrow=c(2,2))
plot(modelo_lin)
### Interpreta√ß√£o: https://data.library.virginia.edu/diagnostic-plots/
# (ES) gr√°fico Residuals vs Fitted (ajustamento dos res√≠duos), comprava a linearidade dos res√≠duos,
# para isso deve ter a linha vermelha na horizontal.
# (DS) Normal Q-Q (gr√°fico QQ Plot) demonstra a normalidade dos res√≠duos, deve ser apoiado pelo teste de Shapiro Wilk
# (EI) Scale Location (valida a homocedasticidade dos res√≠duos)
# o gr√°fico deve apresentar uma distribui√ß√£o dos pontos de forma aleat√≥ria
# (DI) Residuals vs Leverage - outliers e pontos influentes dos res√≠duos
# algo fora do padr√£o ir√° estar acima de linha pontilhada
## Normalidade dos res√≠duos:
## H0 = H√° normalidade nos dados
shapiro.test(modelo_lin$residuals)
## Outliers nos res√≠duos:
## tendo os res√≠duos estandarizados, devemos observar se algum deles passa do valor 3
summary(rstandard(modelo_lin))
## Homocedasticidade (Breusch-Pagan):H0 h√° homocedasticidade
bptest(modelo_lin)
## Independ√™ncia dos res√≠duos (Durbin-Watson): H0 autocorrela√ß√£o positiva
## contudo normalmente utilizado para estudos longitudinais com a seguinte leitura
## A estat√≠stica de teste Durbin-Watson toma valores entre 0 e 4. Ao n√≠vel de signific√¢ncia ÔÅ° de 5%: ## ùëë‚âà0, rejeita-se H0 e existe autocorrela√ß√£o positiva
## ùëë‚âà4, rejeita-se H0 e existe autocorrela√ß√£o negativa
##valores pr√≥ximos de 2, tipicamente entre 1.5 e 2.5, n√£o se rejeita H0, assumindo-se a independ√™ncia
durbinWatsonTest(modelo_lin)
## Resultados do Modelo
summary(modelo_lin)
modelo_lin <- lm(Total_Revolving_Bal ~ Avg_Utilization_Ratio + Dependent_count , conjunto_treinamento)
# An√°lise gr√°fica:
par(mfrow=c(2,2))
plot(modelo_lin)
### Interpreta√ß√£o: https://data.library.virginia.edu/diagnostic-plots/
# (ES) gr√°fico Residuals vs Fitted (ajustamento dos res√≠duos), comprava a linearidade dos res√≠duos,
# para isso deve ter a linha vermelha na horizontal.
# (DS) Normal Q-Q (gr√°fico QQ Plot) demonstra a normalidade dos res√≠duos, deve ser apoiado pelo teste de Shapiro Wilk
# (EI) Scale Location (valida a homocedasticidade dos res√≠duos)
# o gr√°fico deve apresentar uma distribui√ß√£o dos pontos de forma aleat√≥ria
# (DI) Residuals vs Leverage - outliers e pontos influentes dos res√≠duos
# algo fora do padr√£o ir√° estar acima de linha pontilhada
## Normalidade dos res√≠duos:
## H0 = H√° normalidade nos dados
shapiro.test(modelo_lin$residuals)
## Outliers nos res√≠duos:
## tendo os res√≠duos estandarizados, devemos observar se algum deles passa do valor 3
summary(rstandard(modelo_lin))
## Homocedasticidade (Breusch-Pagan):H0 h√° homocedasticidade
bptest(modelo_lin)
## Independ√™ncia dos res√≠duos (Durbin-Watson): H0 autocorrela√ß√£o positiva
## contudo normalmente utilizado para estudos longitudinais com a seguinte leitura
## A estat√≠stica de teste Durbin-Watson toma valores entre 0 e 4. Ao n√≠vel de signific√¢ncia ÔÅ° de 5%: ## ùëë‚âà0, rejeita-se H0 e existe autocorrela√ß√£o positiva
## ùëë‚âà4, rejeita-se H0 e existe autocorrela√ß√£o negativa
##valores pr√≥ximos de 2, tipicamente entre 1.5 e 2.5, n√£o se rejeita H0, assumindo-se a independ√™ncia
durbinWatsonTest(modelo_lin)
## Resultados do Modelo
summary(modelo_lin)
# An√°lise gr√°fica:
par(mfrow=c(2,2))
plot(modelo_lin)
### Interpreta√ß√£o: https://data.library.virginia.edu/diagnostic-plots/
# (ES) gr√°fico Residuals vs Fitted (ajustamento dos res√≠duos), comprava a linearidade dos res√≠duos,
# para isso deve ter a linha vermelha na horizontal.
# (DS) Normal Q-Q (gr√°fico QQ Plot) demonstra a normalidade dos res√≠duos, deve ser apoiado pelo teste de Shapiro Wilk
# (EI) Scale Location (valida a homocedasticidade dos res√≠duos)
# o gr√°fico deve apresentar uma distribui√ß√£o dos pontos de forma aleat√≥ria
# (DI) Residuals vs Leverage - outliers e pontos influentes dos res√≠duos
# algo fora do padr√£o ir√° estar acima de linha pontilhada
## Normalidade dos res√≠duos:
## H0 = H√° normalidade nos dados
shapiro.test(modelo_lin$residuals)
## Outliers nos res√≠duos:
## tendo os res√≠duos estandarizados, devemos observar se algum deles passa do valor 3
summary(rstandard(modelo_lin))
## Homocedasticidade (Breusch-Pagan):H0 h√° homocedasticidade
bptest(modelo_lin)
## Independ√™ncia dos res√≠duos (Durbin-Watson): H0 autocorrela√ß√£o positiva
## contudo normalmente utilizado para estudos longitudinais com a seguinte leitura
## A estat√≠stica de teste Durbin-Watson toma valores entre 0 e 4. Ao n√≠vel de signific√¢ncia ÔÅ° de 5%: ## ùëë‚âà0, rejeita-se H0 e existe autocorrela√ß√£o positiva
## ùëë‚âà4, rejeita-se H0 e existe autocorrela√ß√£o negativa
##valores pr√≥ximos de 2, tipicamente entre 1.5 e 2.5, n√£o se rejeita H0, assumindo-se a independ√™ncia
durbinWatsonTest(modelo_lin)
## Resultados do Modelo
summary(modelo_lin)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(error = FALSE)
options(repos = "https://cran.rstudio.com")
rm(list = ls())
if(!require(pacman)) install.packages("pacman")
library(pacman)
pacman::p_load(tidyverse,
rmarkdown,
knitr,
GGally,
DataExplorer,
gplots,
SmartEDA,
e1071,
caret,
rstatix,
lmtest,
ggpmisc,
car,
psych,
fastDummies
)
p_loaded()
dados <- read.csv("BankChurners.csv")
# excluir as ultimas duas colunas para ocultar o resultado anterior do projeto
dados <- dados[ ,1:21]
#varificar se h√° alguma linha repetida
anyDuplicated(dados)
#Explora√ß√£o da estrutura do data frame - vis√£o 1
ExpData(dados,type=1)
#Explora√ß√£o da estrutura do data frame - vis√£o 2
ExpData(dados,type=2)
#Explora√ß√£o da estrutura do data frame - vis√£o 3
str(dados)
#Explora√ß√£o da estrutura do data frame - vis√£o 4
plot_intro(dados)
# ajuste da vari√°vel Genero como dummy
## Genero
dados$gender_cod <- as.numeric(dados$Gender == "F") #0=male e 1=female
##Estado Civil
dados$marital_cod <- as.numeric(factor(dados$Marital_Status, levels = unique(dados$Marital_Status)))
levels(dados$marital_cod) <- c("Married","Single","Divorced")
table(dados$Marital_Status, dados$marital_cod)
dados$Marital2 <- ifelse(dados$marital_cod == 2, 1, 0)
dados$Marital3 <- ifelse(dados$marital_cod == 3, 1, 0)
# filtrar clientes com utiliza√ß√£o > zero
dados <- dados %>%
filter(Avg_Utilization_Ratio > 0.01) %>%
filter(Marital_Status != "Unknown")
# redu√ß√£o da amostra
dados <- dados %>%
sample_frac(0.05, replace = FALSE)
# Defina a semente para reproduzibilidade
set.seed(56)
# define a propor√ß√£o de dados que ser√° usada para treinamento (por exemplo, 0.7 para 70%)
index <- createDataPartition(dados$Total_Revolving_Bal, p = 0.7, list = FALSE)
# Crie conjuntos de treinamento e teste com base nos √≠ndices
conjunto_treinamento <- dados[index, ]
conjunto_teste <- dados[-index, ]
# validar a igualdade das amostras
boxplot(conjunto_treinamento$Total_Revolving_Bal,conjunto_teste$Total_Revolving_Bal)
# Criar um modelo de Regress√£o Linear
modelo_lin <- lm(Total_Revolving_Bal ~ Avg_Utilization_Ratio + Dependent_count , conjunto_treinamento)
# An√°lise gr√°fica:
par(mfrow=c(2,2))
plot(modelo_lin)
### Interpreta√ß√£o: https://data.library.virginia.edu/diagnostic-plots/
# (ES) gr√°fico Residuals vs Fitted (ajustamento dos res√≠duos), comprava a linearidade dos res√≠duos,
# para isso deve ter a linha vermelha na horizontal.
# (DS) Normal Q-Q (gr√°fico QQ Plot) demonstra a normalidade dos res√≠duos, deve ser apoiado pelo teste de Shapiro Wilk
# (EI) Scale Location (valida a homocedasticidade dos res√≠duos)
# o gr√°fico deve apresentar uma distribui√ß√£o dos pontos de forma aleat√≥ria
# (DI) Residuals vs Leverage - outliers e pontos influentes dos res√≠duos
# algo fora do padr√£o ir√° estar acima de linha pontilhada
## Normalidade dos res√≠duos:
## H0 = H√° normalidade nos dados
shapiro.test(modelo_lin$residuals)
## Outliers nos res√≠duos:
## tendo os res√≠duos estandarizados, devemos observar se algum deles passa do valor 3
summary(rstandard(modelo_lin))
## Homocedasticidade (Breusch-Pagan):H0 h√° homocedasticidade
bptest(modelo_lin)
## Independ√™ncia dos res√≠duos (Durbin-Watson): H0 autocorrela√ß√£o positiva
## contudo normalmente utilizado para estudos longitudinais com a seguinte leitura
## A estat√≠stica de teste Durbin-Watson toma valores entre 0 e 4. Ao n√≠vel de signific√¢ncia ÔÅ° de 5%: ## ùëë‚âà0, rejeita-se H0 e existe autocorrela√ß√£o positiva
## ùëë‚âà4, rejeita-se H0 e existe autocorrela√ß√£o negativa
##valores pr√≥ximos de 2, tipicamente entre 1.5 e 2.5, n√£o se rejeita H0, assumindo-se a independ√™ncia
durbinWatsonTest(modelo_lin)
## Resultados do Modelo
summary(modelo_lin)
# Fazer previs√µes
previsoes <- predict(modelo_nb, conjunto_teste)
summary(modelo_ln)
# Defina a semente para reproduzibilidade
set.seed(56)
# define a propor√ß√£o de dados que ser√° usada para treinamento (por exemplo, 0.7 para 70%)
index <- createDataPartition(dados$Total_Revolving_Bal, p = 0.7, list = FALSE)
# Crie conjuntos de treinamento e teste com base nos √≠ndices
conjunto_treinamento <- dados[index, ]
conjunto_teste <- dados[-index, ]
# validar a igualdade das amostras
boxplot(conjunto_treinamento$Total_Revolving_Bal,conjunto_teste$Total_Revolving_Bal)
# Criar um modelo de Regress√£o Linear
modelo_lin <- lm(Total_Revolving_Bal ~ Avg_Utilization_Ratio + Dependent_count , conjunto_treinamento)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(error = FALSE)
options(repos = "https://cran.rstudio.com")
rm(list = ls())
if(!require(pacman)) install.packages("pacman")
library(pacman)
pacman::p_load(tidyverse,
rmarkdown,
knitr,
GGally,
DataExplorer,
gplots,
SmartEDA,
e1071,
caret,
rstatix,
lmtest,
ggpmisc,
car,
psych,
fastDummies
)
p_loaded()
dados <- read.csv("BankChurners.csv")
# excluir as ultimas duas colunas para ocultar o resultado anterior do projeto
dados <- dados[ ,1:21]
#varificar se h√° alguma linha repetida
anyDuplicated(dados)
#Explora√ß√£o da estrutura do data frame - vis√£o 1
ExpData(dados,type=1)
#Explora√ß√£o da estrutura do data frame - vis√£o 2
ExpData(dados,type=2)
#Explora√ß√£o da estrutura do data frame - vis√£o 3
str(dados)
#Explora√ß√£o da estrutura do data frame - vis√£o 4
plot_intro(dados)
# ajuste da vari√°vel Genero como dummy
## Genero
dados$gender_cod <- as.numeric(dados$Gender == "F") #0=male e 1=female
##Estado Civil
dados$marital_cod <- as.numeric(factor(dados$Marital_Status, levels = unique(dados$Marital_Status)))
levels(dados$marital_cod) <- c("Married","Single","Divorced")
table(dados$Marital_Status, dados$marital_cod)
dados$Marital2 <- ifelse(dados$marital_cod == 2, 1, 0)
dados$Marital3 <- ifelse(dados$marital_cod == 3, 1, 0)
# filtrar clientes com utiliza√ß√£o > zero
dados <- dados %>%
filter(Avg_Utilization_Ratio > 0.01) %>%
filter(Marital_Status != "Unknown")
# redu√ß√£o da amostra
dados <- dados %>%
sample_frac(0.05, replace = FALSE)
# Defina a semente para reproduzibilidade
set.seed(56)
# define a propor√ß√£o de dados que ser√° usada para treinamento (por exemplo, 0.7 para 70%)
index <- createDataPartition(dados$Total_Revolving_Bal, p = 0.7, list = FALSE)
# Crie conjuntos de treinamento e teste com base nos √≠ndices
conjunto_treinamento <- dados[index, ]
conjunto_teste <- dados[-index, ]
# validar a igualdade das amostras
boxplot(conjunto_treinamento$Total_Revolving_Bal,conjunto_teste$Total_Revolving_Bal)
# Criar um modelo de Regress√£o Linear
modelo_lin <- lm(Total_Revolving_Bal ~ Avg_Utilization_Ratio + Dependent_count , conjunto_treinamento)
# An√°lise gr√°fica:
par(mfrow=c(2,2))
plot(modelo_lin)
### Interpreta√ß√£o: https://data.library.virginia.edu/diagnostic-plots/
# (ES) gr√°fico Residuals vs Fitted (ajustamento dos res√≠duos), comprava a linearidade dos res√≠duos,
# para isso deve ter a linha vermelha na horizontal.
# (DS) Normal Q-Q (gr√°fico QQ Plot) demonstra a normalidade dos res√≠duos, deve ser apoiado pelo teste de Shapiro Wilk
# (EI) Scale Location (valida a homocedasticidade dos res√≠duos)
# o gr√°fico deve apresentar uma distribui√ß√£o dos pontos de forma aleat√≥ria
# (DI) Residuals vs Leverage - outliers e pontos influentes dos res√≠duos
# algo fora do padr√£o ir√° estar acima de linha pontilhada
## Normalidade dos res√≠duos:
## H0 = H√° normalidade nos dados
shapiro.test(modelo_lin$residuals)
## Outliers nos res√≠duos:
## tendo os res√≠duos estandarizados, devemos observar se algum deles passa do valor 3
summary(rstandard(modelo_lin))
## Homocedasticidade (Breusch-Pagan):H0 h√° homocedasticidade
bptest(modelo_lin)
## Independ√™ncia dos res√≠duos (Durbin-Watson): H0 autocorrela√ß√£o positiva
## contudo normalmente utilizado para estudos longitudinais com a seguinte leitura
## A estat√≠stica de teste Durbin-Watson toma valores entre 0 e 4. Ao n√≠vel de signific√¢ncia ÔÅ° de 5%: ## ùëë‚âà0, rejeita-se H0 e existe autocorrela√ß√£o positiva
## ùëë‚âà4, rejeita-se H0 e existe autocorrela√ß√£o negativa
##valores pr√≥ximos de 2, tipicamente entre 1.5 e 2.5, n√£o se rejeita H0, assumindo-se a independ√™ncia
durbinWatsonTest(modelo_lin)
## Resultados do Modelo
summary(modelo_lin)
# Fazer previs√µes
previsoes <- predict(modelo_nb, conjunto_teste)
# Fazer previs√µes
previsoes <- predict(modelo_lin, conjunto_teste)
ggplot(data = dados, mapping = aes(x = Avg_Utilization_Ratio, y = Total_Revolving_Bal)) +
geom_point() +
geom_smooth(method = "lm", col = "green") +
stat_poly_eq(aes(label = paste(after_stat(eq.label), after_stat(adj.rr.label),
sep = "*plain(\",\")~~")),
label.x = 0.5, label.y = 0.05,
parse = TRUE, coef.digits = 5) +
theme_classic()
### Avalia√ß√£o pela diferen√ßa da previs√£o - crit√©rio exclusivamente gerencial!!!
conjunto_teste$dif <- conjunto_teste$Vendas-conjunto_teste$Vendas_pr
previsoes
a <- as.data.frame(previsoes)
View(a)
table(conjunto_teste$Total_Revolving_Bal,previoes)
table(conjunto_teste$Total_Revolving_Bal,previsoes)
conjunto_teste$prev <- previsoes
View(conjunto_teste)
conjunto_teste$dif <- conjunto_teste$Total_Revolving_Bal-previsoes
summary(conjunto_teste$dif)
t.test(conjunto_teste$dif)
### Avalia√ß√£o pela diferen√ßa da previs√£o - crit√©rio exclusivamente gerencial!!!
conjunto_teste$prev <- previsoes
View(conjunto_teste)
conjunto_teste$dif <- conjunto_teste$Total_Revolving_Bal-previsoes
summary(conjunto_teste$dif)
t.test(conjunto_teste$dif)
### Avalia√ß√£o pela diferen√ßa da previs√£o - crit√©rio exclusivamente gerencial!!!
conjunto_teste$prev <- previsoes
conjunto_teste$dif <- conjunto_teste$Total_Revolving_Bal-previsoes
summary(conjunto_teste$dif)
t.test(conjunto_teste$dif)
